{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOohok+7+I6WGjA4b3XP//G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stefantatur/AI-agent/blob/main/Langgraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Инициализация и настройка окружения"
      ],
      "metadata": {
        "id": "XxPnbp_2LaBY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "1w2Qm3T4LWQs",
        "outputId": "c5bf4ec0-9780-4d54-a526-fc3c82b3f70f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-4269b0599644>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlanggraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMessagesState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os, getpass\n",
        "import requests\n",
        "from IPython.display import Image, display\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import MessagesState\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import START, StateGraph\n",
        "from langgraph.prebuilt import tools_condition\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var): # проверяет существует ли переменная окружения\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \") # если нет, создает новую\n",
        "\n",
        "# стараемся не хардкодить и задавать все важные ключи в начале\n",
        "_set_env(\"OPENAI_API_KEY\") # используем set_env для безопасного чтения ключей\n",
        "_set_env(\"LANGCHAIN_API_KEY\") # Ключ для сервисов LangChain\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 2. Определение арифметических инструментов"
      ],
      "metadata": {
        "id": "dog6YV19LrDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Умножает два числа\"\"\"\n",
        "    return a * b\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Складывает два числа\"\"\"\n",
        "    return a + b\n",
        "\n",
        "def divide(a: int, b: int) -> float:\n",
        "    \"\"\"Делит число a на число b\"\"\"\n",
        "    if b == 0:\n",
        "        raise ValueError(\"Делить на ноль нельзя!\") # небольшая обработка исключений\n",
        "    return a / b\n",
        "\n",
        "tools = [add, multiply, divide] # наш функционал"
      ],
      "metadata": {
        "id": "FScTpnbyLu7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Настройка языковой модели"
      ],
      "metadata": {
        "id": "8VhJp0VtLxlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o\",\n",
        "                 openai_proxy=\"http://43.153.39.191:13001\",\n",
        "                 temperature=0)\n",
        "\n",
        "''' параметр temperature 0 установлен,\n",
        "так как при конвертации валют,\n",
        "очень важно получать четкие ответы '''\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False) # привязываем инструменты к llm-ки и отключаем параллельный вызов функций\n",
        "sys_msg = SystemMessage(content=\"Вы помощник для арифметики и конвертации валют.\") # задаем роль и поведение модели"
      ],
      "metadata": {
        "id": "6YRkdpQAL4XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Функция ассистента"
      ],
      "metadata": {
        "id": "iX60eu6UMFhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assistant(state: MessagesState):\n",
        "    print(f\"\\n--- Текущий state ---\\n{state['messages'][-1]}\\n---\") # вывод логов и вывод в консоль последнее сообщение из текущего состояния\n",
        "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]} # обновленный словарь\n",
        "\n",
        "'''Метод .invoke() в LangChain — это основной способ выполнения запросов к языковой модели - это часть api\n",
        "\n",
        ".invoke() — для одиночных запросов (как в вашем коде)\n",
        "\n",
        ".generate() — для параллельных запросов к модели (например, обработка списка вопросов) '''"
      ],
      "metadata": {
        "id": "9Nj-Do7QMHRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Доп функционал (конвертация валют)"
      ],
      "metadata": {
        "id": "zySUYEkFMNLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_currency(amount: float, from_curr: str, to_curr: str) -> float:\n",
        "    proxies = {\"http\": \"http://43.153.39.191:13001\", \"https\": \"http://43.153.39.191:13001\"} # здесь нужен хороший proxy\n",
        "    try:\n",
        "        response = requests.get(f\"https://api.exchangerate-api.com/v4/latest/{from_curr}\", proxies=proxies, timeout=10)\n",
        "        data = response.json() # Парсит JSON-ответ API\n",
        "        return amount * data[\"rates\"][to_curr]\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"Ошибка: {e}\")"
      ],
      "metadata": {
        "id": "uq2i-mE5MP7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Логика маршрутизации"
      ],
      "metadata": {
        "id": "Lej78m5_MSWZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# реализует логику ветвления и обработки запросов по конвертации валют\n",
        "\n",
        "def router(state: MessagesState) -> str:\n",
        "\n",
        "    ''' Определяет, нужно ли обрабатывать запрос как конвертацию валют\n",
        "     или использовать обычные инструменты (арифметику) '''\n",
        "\n",
        "    last_msg = state[\"messages\"][-1].content\n",
        "    if any(word in last_msg.lower() for word in [\"usd\", \"eur\", \"руб\", \"конверт\"]):\n",
        "        return \"currency\"\n",
        "    return \"tools\"\n",
        "\n",
        "def currency_node(state: MessagesState):\n",
        "\n",
        "    '''Обрабатывает запросы на конвертацию валют, вызывая внешний API '''\n",
        "\n",
        "    try:\n",
        "        query = state[\"messages\"][-1].content\n",
        "        parts = query.split()\n",
        "        amount, from_curr, to_curr = float(parts[0]), parts[1], parts[3]\n",
        "        result = convert_currency(amount, from_curr, to_curr)\n",
        "        return {\"messages\": [HumanMessage(content=f\"Результат: {amount} {from_curr} = {result:.2f} {to_curr}\")]}\n",
        "    except Exception as e:\n",
        "        return {\"messages\": [HumanMessage(content=f\"Ошибка: {str(e)}\")]}"
      ],
      "metadata": {
        "id": "9QOjQRgBMWlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Построение графа"
      ],
      "metadata": {
        "id": "tuWSy_twMYQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(MessagesState) # создаем конструктор графа, который будет содержать узлы (ноды) и связи между ними\n",
        "\n",
        "builder.add_node(\"assistant\", assistant) # конструктор графа, который будет содержать узлы (ноды) и связи между ними\n",
        "builder.add_node(\"tools\", ToolNode(tools)) # Обрабатывает арифметические операции\n",
        "builder.add_node(\"currency\", currency_node) # работает с валютами\n",
        "\n",
        "'''Настройка связей '''\n",
        "\n",
        "builder.add_edge(START, \"assistant\") # Стартовая точка\n",
        "builder.add_conditional_edges(\"assistant\", router, {\"tools\": \"tools\", \"currency\": \"currency\"}) # ветвление\n",
        "builder.add_edge(\"tools\", \"assistant\") # После выполнения tools возвращаем управление агенту\n",
        "builder.add_edge(\"currency\", \"assistant\") # После выполнения currency возвращаем управление агенту\n",
        "\n",
        "final_graph = builder.compile() # создание графа"
      ],
      "metadata": {
        "id": "BsiFEt7-Ma6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Тестирование"
      ],
      "metadata": {
        "id": "8frlDcbmMinX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    \"Сложи 5 и 3, затем раздели результат на 2\",\n",
        "    \"Конвертируй 100 USD в EUR\",\n",
        "    \"Умножь 10 на 0, затем раздели на 0\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    print(f\"\\n Запрос: '{query}'\")\n",
        "    result = final_graph.invoke({\"messages\": [HumanMessage(content=query)]}) # граф получает запрос как первое сообщение.\n",
        "    print(f\"Ответ: {result['messages'][-1].content}\")"
      ],
      "metadata": {
        "id": "F0cGnIjcMmmm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}